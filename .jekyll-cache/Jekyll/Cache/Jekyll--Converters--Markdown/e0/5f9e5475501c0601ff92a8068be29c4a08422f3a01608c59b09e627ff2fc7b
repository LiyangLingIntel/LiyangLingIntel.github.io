I"\<p>[toc]</p>

<ul>
  <li>map执行中内存溢出
map执行中内存溢出代表了所有map类型的操作，包括：<code class="highlighter-rouge">flatMap</code>，<code class="highlighter-rouge">filter</code>，<code class="highlighter-rouge">mapPatitions</code>等。</li>
  <li>shuffle后内存溢出
shuffle后内存溢出的shuffle操作包括<code class="highlighter-rouge">join</code>，<code class="highlighter-rouge">reduceByKey</code>，<code class="highlighter-rouge">repartition</code>等操作。</li>
</ul>

<h3 id="1-spark-内存模型">1. Spark 内存模型：</h3>

<p>Spark在一个<u>Executor中的内存</u>分为三块，一块是execution内存，一块是storage内存，一块是other内存。</p>

<ul>
  <li>execution内存是执行内存，文档中说join，aggregate都在这部分内存中执行，shuffle的数据也会先缓存在这个内存中，满了再写入磁盘，能够减少IO。其实map过程也是在这个内存中执行的。</li>
  <li>storage内存是存储broadcast，cache，persist数据的地方。</li>
  <li>other内存是程序执行时预留给自己的内存。</li>
</ul>

<p>execution和storage是Spark Executor中内存的大户，other占用内存相对少很多。</p>

<p>在spark-1.6.0以前的版本，execution和storage的内存分配是固定的，使用的参数配置分别是<code class="highlighter-rouge">spark.shuffle.memoryFraction</code>(execution内存占Executor总内存大小，default 0.2)和<code class="highlighter-rouge">spark.storage.memoryFraction</code>(storage内存占Executor内存大小，default 0.6). 因为是1.6.0以前这两块内存是互相隔离的，这就导致了Executor的内存利用率不高，而且需要根据Application的具体情况，使用者自己来调节这两个参数才能优化Spark的内存使用。</p>

<p>在spark-1.6.0以上的版本，execution内存和storage内存可以相互借用，提高了内存的Spark中内存的使用率，同时也减少了OOM的情况。</p>

<p>在Spark-1.6.0后加入了<strong>堆外内存</strong>，进一步优化了Spark的内存使用，堆外内存使用JVM堆以外的内存，不会被gc回收，可以减少频繁的full gc，所以在Spark程序中，会长时间逗留再Spark程序中的大内存对象可以使用堆外内存存储。
使用堆外内存有两种方式，
一种是在rdd调用persist的时候传入参数<code class="highlighter-rouge">StorageLevel.OFF_HEAP</code>，这种使用方式需要配合Tachyon一起使用。
另外一种是使用Spark自带的<code class="highlighter-rouge">spark.memory.offHeap.enabled</code> 配置为true进行使用，但是这种方式在1.6.0的版本还不支持使用，只是多了这个参数，在以后的版本中会开放。</p>

<p>OOM的问题通常出现在execution这块内存中，因为storage这块内存在存放数据满了之后，会直接丢弃内存中旧的数据，对性能有影响但是不会有OOM的问题。</p>

<h3 id="2-内存溢出解决方法">2. 内存溢出解决方法：</h3>

<ol>
  <li>
    <p>map过程产生大量对象导致内存溢出：</p>

    <p>这种溢出的原因是在单个map中产生了大量的对象导致的，例如：</p>

    <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre></td><td class="rouge-code"><pre> <span class="nv">rdd</span><span class="o">.</span><span class="py">map</span><span class="o">(</span><span class="n">x</span><span class="k">=&gt;</span><span class="nf">for</span><span class="o">(</span><span class="n">i</span> <span class="k">&lt;-</span> <span class="mi">1</span> <span class="n">to</span> <span class="mi">10000</span><span class="o">)</span> <span class="k">yield</span> <span class="nv">i</span><span class="o">.</span><span class="py">toString</span><span class="o">)</span>
</pre></td></tr></tbody></table></code></pre></div>    </div>

    <p>这个操作在rdd中，每个对象都产生了10000个对象，这肯定很容易产生内存溢出的问题。针对这种问题，在不增加内存的情况下，可以通过减少每个Task的大小，以便达到每个Task即使产生大量的对象Executor的内存也能够装得下。<strong>具体做法</strong>可以在会产生大量对象的map操作之前调用<code class="highlighter-rouge">repartition</code>方法，分区成<u>更小的块</u>传入map。例如：</p>

    <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre></td><td class="rouge-code"><pre> <span class="nv">rdd</span><span class="o">.</span><span class="py">repartition</span><span class="o">(</span><span class="mi">10000</span><span class="o">).</span><span class="py">map</span><span class="o">(</span><span class="n">x</span><span class="k">=&gt;</span><span class="nf">for</span><span class="o">(</span><span class="n">i</span> <span class="k">&lt;-</span> <span class="mi">1</span> <span class="n">to</span> <span class="mi">10000</span><span class="o">)</span> <span class="k">yield</span> <span class="nv">i</span><span class="o">.</span><span class="py">toString</span><span class="o">)</span>
</pre></td></tr></tbody></table></code></pre></div>    </div>

    <p>面对这种问题注意，不能使用<code class="highlighter-rouge">rdd.coalesce</code>方法，这个方法只能减少分区，不能增加分区，不会有shuffle的过程。</p>
  </li>
  <li>
    <p>数据不平衡导致内存溢出：</p>

    <p>数据不平衡除了有可能导致内存溢出外，也有可能导致性能的问题，解决方法和上面说的类似，就是调用<code class="highlighter-rouge">repartition</code>重新分区。这里就不再累赘了。</p>
  </li>
  <li>
    <p><code class="highlighter-rouge">coalesce</code>调用导致内存溢出：</p>

    <p>因为hdfs中不适合存小问题，所以Spark计算后如果产生的文件太小，我们会调用<code class="highlighter-rouge">coalesce</code>合并文件再存入hdfs中。但是这会导致一个问题，例如在<code class="highlighter-rouge">coalesce</code>之前有100个文件，这也意味着能够有100个Task，现在调用<code class="highlighter-rouge">coalesce(10)</code>，最后只产生10个文件，因为<code class="highlighter-rouge">coalesce</code>并不是shuffle操作，这意味着<code class="highlighter-rouge">coalesce</code>并不是按照我原本想的那样先执行100个Task，再将Task的执行结果合并成10个，而是从头到位只有10个Task在执行，原本100个文件是分开执行的，现在每个Task同时一次读取10个文件，使用的内存是原来的10倍，这导致了OOM。解决这个问题的方法是令程序按照我们想的先执行100个Task再将结果合并成10个文件，这个问题同样可以通过<code class="highlighter-rouge">repartition</code>解决，调用<code class="highlighter-rouge">repartition(10)</code>，因为这就有一个shuffle的过程，shuffle前后是两个Stage，一个100个分区，一个是10个分区，就能按照我们的想法执行。</p>
  </li>
  <li>
    <p>shuffle后内存溢出:</p>

    <p>shuffle内存溢出的情况可以说都是shuffle后，<u>单个文件过大</u>导致的。
在Spark中，<code class="highlighter-rouge">join</code>，<code class="highlighter-rouge">reduceByKey</code>这一类型的过程，都会有shuffle的过程，在shuffle的使用，需要传入一个partitioner，大部分Spark中的shuffle操作，默认的partitioner都是<code class="highlighter-rouge">HashPatitioner</code>，默认值是父RDD中<u>最大的分区数</u>, 这个参数通过下面两个参数控制:</p>

    <ul>
      <li>RDD: <code class="highlighter-rouge">spark.default.parallelism</code></li>
      <li>DataFrame: <code class="highlighter-rouge">spark.sql.shuffle.partitions</code></li>
    </ul>

    <p><code class="highlighter-rouge">spark.default.parallelism</code>参数只对<code class="highlighter-rouge">HashPartitioner</code>有效，所以如果是别的Partitioner或者自己实现的Partitioner就不能使用<code class="highlighter-rouge">spark.default.parallelism</code>这个参数来控制shuffle的并发量了。如果是别的partitioner导致的shuffle内存溢出，就需要从partitioner的代码增加partitions的数量。</p>
  </li>
  <li>
    <p>standalone模式下资源分配不均匀导致内存溢出：
 在standalone的模式下如果配置了<code class="highlighter-rouge">--total-executor-cores</code> 和 <code class="highlighter-rouge">--executor-memory</code> 这两个参数，但是没有配置<code class="highlighter-rouge">--executor-cores</code>这个参数的话，就有可能导致，每个Executor的<strong>memory</strong>是一样的，但是<strong>cores</strong>的数量不同，那么在cores数量多的Executor中，由于能够同时执行多个Task，就容易导致内存溢出的情况。这种情况的解决方法就是同时配置<code class="highlighter-rouge">--executor-cores</code>或者<code class="highlighter-rouge">spark.executor.cores</code>参数，确保Executor资源分配均匀。</p>
  </li>
  <li>
    <p>在RDD中，共用对象能够减少OOM的情况：</p>

    <p>这个比较特殊，有一种情况，类似这样</p>

    <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre></td><td class="rouge-code"><pre><span class="nv">rdd</span><span class="o">.</span><span class="py">flatMap</span><span class="o">(</span><span class="n">x</span><span class="k">=&gt;</span><span class="nf">for</span><span class="o">(</span><span class="n">i</span> <span class="k">&lt;-</span> <span class="mi">1</span> <span class="n">to</span> <span class="mi">1000</span><span class="o">)</span> <span class="nf">yield</span> <span class="o">(</span><span class="s">"key"</span><span class="o">,</span><span class="s">"value"</span><span class="o">))</span>
</pre></td></tr></tbody></table></code></pre></div>    </div>

    <p>导致OOM，但是在同样的情况下，使用</p>

    <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre></td><td class="rouge-code"><pre><span class="nv">rdd</span><span class="o">.</span><span class="py">flatMap</span><span class="o">(</span><span class="n">x</span><span class="k">=&gt;</span><span class="nf">for</span><span class="o">(</span><span class="n">i</span> <span class="k">&lt;-</span> <span class="mi">1</span> <span class="n">to</span> <span class="mi">1000</span><span class="o">)</span> <span class="k">yield</span> <span class="s">"key"</span><span class="o">+</span><span class="s">"value"</span><span class="o">)</span>
</pre></td></tr></tbody></table></code></pre></div>    </div>

    <p>就不会有OOM的问题，这是因为每次<code class="highlighter-rouge">("key","value")</code>都产生一个Tuple对象，而”key”+”value”，不管多少个，都只有一个对象，指向常量池。具体测试如下：</p>

    <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre></td><td class="rouge-code"><pre><span class="n">scala</span><span class="o">&gt;</span> <span class="o">(</span><span class="s">"key"</span><span class="o">,</span><span class="s">"value"</span><span class="o">)</span> <span class="nf">eq</span> <span class="o">(</span><span class="s">"key"</span><span class="o">,</span><span class="s">"value"</span><span class="o">)</span>
<span class="n">res0</span><span class="k">:</span> <span class="kt">false</span>
   
<span class="n">scala</span><span class="o">&gt;</span> <span class="s">"key"</span><span class="o">+</span><span class="s">"value"</span> <span class="n">eq</span> <span class="s">"key"</span><span class="o">+</span><span class="s">"value"</span>
<span class="n">res0</span><span class="k">:</span> <span class="kt">true</span>
</pre></td></tr></tbody></table></code></pre></div>    </div>

    <p>这个例子说明(“key”,”value”)和(“key”,”value”)在内存中是存在不同位置的,也就是存了两份,但是”key”+”value”虽然出现了两次,但是只存了一份,在同一个地址,这用到了JVM常量池的知识. 于是乎,如果RDD中有大量的重复数据,或者Array中需要存大量重复数据的时候我们都可以将重复数据转化为String,能够有效的减少内存使用.</p>
  </li>
</ol>

<h3 id="3-优化策略">3. 优化策略：</h3>

<p>这一部分主要记录一下到spark-1.6.1版本，笔者觉得有优化性能作用的一些参数配置和一些代码优化技巧，在参数优化部分，如果笔者觉得默认值是最优的了，这里就不再记录。</p>
<h4 id="代码优化技巧">代码优化技巧：</h4>
<ol>
  <li>
    <p>使用<code class="highlighter-rouge">mapPartitions</code>代替大部分<code class="highlighter-rouge">map</code>操作，或者连续使用的<code class="highlighter-rouge">map</code>操作：</p>

    <p>这里需要稍微讲一下RDD和DataFrame的区别。</p>

    <ul>
      <li>RDD强调的是<strong>不可变对象</strong>，每个RDD都是不可变的，当调用RDD的map类型操作的时候，都是产生一个新的对象，这就导致了一个问题，如果对一个RDD调用大量的map类型操作的话，每个map操作会产生一个到多个RDD对象，这虽然不一定会导致内存溢出，但是会产生大量的中间数据，<u>增加了gc操作</u>。另外RDD在调用action操作的时候，会出发Stage的划分，但是在每个Stage内部可优化的部分是不会进行优化的，例如<code class="highlighter-rouge">rdd.map(_+1).map(_+1)</code>，这个操作在数值型RDD中是等价于rdd.map(_+2)的，但是RDD内部不会对这个过程进行优化。</li>
      <li>DataFrame则不同，DataFrame由于有类型信息所以是<strong>可变的</strong>，并且在可以使用sql的程序中，都有除了解释器外，都会有一个sql优化器，DataFrame也不例外，有一个优化器Catalyst，具体介绍看后面参考的文章。</li>
    </ul>

    <p>上面说到的这些RDD的弊端，有一部分就可以使用<code class="highlighter-rouge">mapPartitions</code>进行优化，<code class="highlighter-rouge">mapPartitions</code>可以同时替代<code class="highlighter-rouge">rdd.map</code>, <code class="highlighter-rouge">rdd.filter</code>, <code class="highlighter-rouge">rdd.flatMap</code>的作用，所以在长操作中，可以在<code class="highlighter-rouge">mapPartitons</code>中将RDD大量的操作写在一起，避免产生大量的中间rdd对象，另外是mapPartitions在一个partition中可以复用可变类型，这也能够避免频繁的创建新对象。使用mapPartitions的弊端就是牺牲了代码的易读性。</p>
  </li>
  <li>
    <p><code class="highlighter-rouge">broadcast join</code>和普通<code class="highlighter-rouge">join</code>：</p>

    <p>在大数据分布式系统中，大量数据的移动对性能的影响也是巨大的。基于这个思想，在两个RDD进行join操作的时候，如果其中一个RDD相对小很多，可以将小的RDD进行<code class="highlighter-rouge">collect</code>操作然后设置为<code class="highlighter-rouge">broadcast</code>变量，这样做之后，另一个RDD就可以使用map操作进行join，这样能够有效的减少相对大很多的那个RDD的数据移动。</p>
  </li>
  <li>
    <p>先<code class="highlighter-rouge">filter</code>在<code class="highlighter-rouge">join</code>：</p>

    <p>这个就是<strong>谓词下推</strong>，这个很显然，filter之后再join，shuffle的数据量会减少，这里提一点是spark-sql的优化器已经对这部分有优化了，不需要用户显示的操作，个人实现rdd的计算的时候需要注意这个。</p>
  </li>
  <li>
    <p>partitonBy优化：</p>

    <p>这一部分在另一篇文章《spark partitioner使用技巧 》有详细介绍，这里不说了。</p>
  </li>
  <li>
    <p>combineByKey的使用：
 这个操作在Map-Reduce中也有，这里举个例子：<code class="highlighter-rouge">rdd.groupByKey().mapValue(_.sum)</code>比<code class="highlighter-rouge">rdd.reduceByKey</code>的效率低，原因如下两幅图所示(网上盗来的，侵删)</p>

    <p><img src="https://images2017.cnblogs.com/blog/739727/201801/739727-20180126174937069-1579617042.png" width="500" /></p>

    <p><img src="https://images2017.cnblogs.com/blog/739727/201801/739727-20180126175121959-313725154.png" width="500" /></p>

    <p>上下两幅图的区别就是上面那幅有<code class="highlighter-rouge">combineByKey</code>的过程减少了shuffle的数据量，下面的没有。<code class="highlighter-rouge">combineByKey</code>是key-value型rdd自带的API，可以直接使用。</p>
  </li>
  <li>
    <p>在内存不足的使用，使用<code class="highlighter-rouge">rdd.persist(StorageLevel.MEMORY_AND_DISK_SER)</code>代替<code class="highlighter-rouge">rdd.cache()</code></p>

    <p><code class="highlighter-rouge">rdd.cache()</code>和<code class="highlighter-rouge">rdd.persist(Storage.MEMORY_ONLY)</code>是等价的，在内存不足的时候<code class="highlighter-rouge">rdd.cache()</code>的数据会丢失，<u>再次使用的时候会重算</u>，而<code class="highlighter-rouge">rdd.persist(StorageLevel.MEMORY_AND_DISK_SER)</code>在内存不足的时候会存储在磁盘，避免重算，只是消耗点IO时间。</p>
  </li>
  <li>
    <p>在spark使用hbase的时候，spark和hbase搭建在同一个集群：</p>

    <p>在spark结合hbase的使用中，spark和hbase最好搭建在同一个集群上上，或者spark的集群节点能够覆盖hbase的所有节点。hbase中的数据存储在HFile中，通常单个HFile都会比较大，另外Spark在读取Hbase的数据的时候，不是按照一个HFile对应一个RDD的分区，而是一个region对应一个RDD分区。所以在Spark读取Hbase的数据时，通常单个RDD都会比较大，如果不是搭建在同一个集群，数据移动会耗费很多的时间。</p>
  </li>
</ol>

<h4 id="参数优化部分">参数优化部分：</h4>

<ol>
  <li><code class="highlighter-rouge">spark.driver.memory</code> (default 1G)：</li>
</ol>

<p>这个参数用来设置Driver的内存。在Spark程序中，SparkContext，DAGScheduler都是运行在Driver端的。对应rdd的Stage切分也是在Driver端运行，如果用户自己写的程序有过多的步骤，切分出过多的Stage，这部分信息消耗的是Driver的内存，这个时候就需要调大Driver的内存。</p>

<ol>
  <li>
    <p><code class="highlighter-rouge">spark.rdd.compress</code> (default false) ：</p>

    <p>这个参数在内存吃紧的时候，又需要persist数据有良好的性能，就可以设置这个参数为true，这样在使用<code class="highlighter-rouge">persist(StorageLevel.MEMORY_ONLY_SER)</code>的时候，就能够压缩内存中的rdd数据。减少内存消耗，就是在使用的时候会占用CPU的解压时间。</p>
  </li>
  <li>
    <p><code class="highlighter-rouge">spark.serializer</code> (default <code class="highlighter-rouge">org.apache.spark.serializer.JavaSerializer</code> )</p>

    <p>建议设置为 <code class="highlighter-rouge">org.apache.spark.serializer.KryoSerializer</code>，因为KryoSerializer比JavaSerializer快，但是有可能会有些Object会序列化失败，这个时候就需要显示的对序列化失败的类进行KryoSerializer的注册，这个时候要配置spark.kryo.registrator参数或者使用参照如下代码：</p>

    <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre></td><td class="rouge-code"><pre><span class="n">valconf</span><span class="k">=</span><span class="nf">newSparkConf</span><span class="o">().</span><span class="py">setMaster</span><span class="o">(...).</span><span class="py">setAppName</span><span class="o">(...)</span>
<span class="nv">conf</span><span class="o">.</span><span class="py">registerKryoClasses</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="n">classOf</span><span class="o">[</span><span class="kt">MyClass1</span><span class="o">],</span><span class="n">classOf</span><span class="o">[</span><span class="kt">MyClass2</span><span class="o">]))</span>
<span class="n">valsc</span> <span class="k">=</span><span class="nf">newSparkContext</span><span class="o">(</span><span class="n">conf</span><span class="o">)</span>
</pre></td></tr></tbody></table></code></pre></div>    </div>
  </li>
  <li>
    <p><code class="highlighter-rouge">spark.memory.storageFraction</code> (default 0.5)</p>

    <p>‘这个参数设置内存表示 Executor内存中 storage/(storage+execution)，虽然spark-1.6.0+的版本内存storage和execution的内存已经是可以互相借用的了，但是借用和赎回也是需要消耗性能的，所以如果明知道程序中storage是多是少就可以调节一下这个参数。</p>
  </li>
  <li>
    <p><code class="highlighter-rouge">spark.locality.wait</code> (default 3s)：</p>

    <p>spark中有4种本地化执行level，
<code class="highlighter-rouge">PROCESS_LOCAL</code>-&gt;<code class="highlighter-rouge">NODE_LOCAL</code>-&gt;<code class="highlighter-rouge">RACK_LOCAL</code>-&gt;<code class="highlighter-rouge">ANY</code>,
一个task执行完，等待spark.locality.wait时间如果，第一次等待PROCESS的Task到达，如果没有，等待任务的等级下调到NODE再等待spark.locality.wait时间，依次类推，直到ANY。分布式系统是否能够很好的执行本地文件对性能的影响也是很大的。如果RDD的每个分区数据比较多，每个分区处理时间过长，就应该把 spark.locality.wait 适当调大一点，让Task能够有更多的时间等待本地数据。特别是在使用persist或者cache后，这两个操作过后，在本地机器调用内存中保存的数据效率会很高，但是如果需要跨机器传输内存中的数据，效率就会很低。</p>
  </li>
  <li>
    <p><code class="highlighter-rouge">spark.speculation</code> (default false):</p>

    <p>一个大的集群中，每个节点的性能会有差异，spark.speculation这个参数表示空闲的资源节点会不会尝试执行还在运行，并且运行时间过长的Task，避免单个节点运行速度过慢导致整个任务卡在一个节点上。这个参数最好设置为true。与之相配合可以一起设置的参数有<code class="highlighter-rouge">spark.speculation.*</code>开头的参数。参考中有文章详细说明这个参数。</p>
  </li>
</ol>

<p>参考：</p>
<ol>
  <li>http://www.jianshu.com/p/c0181667daa0</li>
  <li>http://www.csdn.net/article/2015-06-18/2824958</li>
  <li>https://chenzhongpu.gitbooks.io/bigdatanotes/content/SparkSQLOptimizer/index.html</li>
  <li>http://book.51cto.com/art/201409/453045.html</li>
</ol>

<p>原文链接：https://blog.csdn.net/yhb315279058/article/details/51035631</p>

:ET