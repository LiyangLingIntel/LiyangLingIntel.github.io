I"v6<blockquote>
  <p>没有测量，就没有科学。</p>

  <p>—— 门捷列夫</p>
</blockquote>

<p>[TOC]</p>

<h3 id="1-评估指标的局限">1. 评估指标的局限</h3>

<h4 id="11-基本概念">1.1 基本概念</h4>

<ul>
  <li>
    <p><strong>混淆矩阵</strong></p>

    <table>
      <thead>
        <tr>
          <th style="text-align: center"> </th>
          <th style="text-align: center">Actual: Positive</th>
          <th style="text-align: center">Actual: Negative</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td style="text-align: center"><strong>Predicted: True</strong></td>
          <td style="text-align: center">TP</td>
          <td style="text-align: center">FP</td>
        </tr>
        <tr>
          <td style="text-align: center"><strong>Predicted: False</strong></td>
          <td style="text-align: center">FN</td>
          <td style="text-align: center">TN</td>
        </tr>
      </tbody>
    </table>

    <ul>
      <li><strong>TP</strong>: 将正类预测为正类</li>
      <li><strong>TN</strong>: 将负类预测为负类</li>
      <li><strong>FP</strong>: 将负类预测为正类 → <strong>误报</strong> (Type I error).</li>
      <li><strong>FN</strong>: 将正类预测为负类数 → <strong>漏报</strong> (Type II error).</li>
      <li>记忆技巧：<strong>P</strong>和<strong>N</strong>分别表示预测结果的Positive或者Negative，而<strong>T</strong>和<strong>F</strong>则表示对预测结果的正误的判断。例如<strong>FN</strong>表示预测为负的这个预测是错误的，即把正类预测为负。</li>
    </ul>
  </li>
</ul>

<p>由混淆矩阵，我们可以得出几个评估指标</p>

<ul>
  <li>
    <p><strong>准确率</strong>(Accuracy) = $\tfrac{TP+TN}{TP+FN+FP+TN}$</p>

    <p>针对<strong>全集</strong>而言， 表示预测为正的样本在所有样本中的比重</p>
  </li>
  <li>
    <p><strong>精确率</strong>(Precision) = $\tfrac{TP}{TP+FP}$</p>

    <p>针对我们<strong>预测结果</strong>而言的，表示的是预测为正的样本中有多少是真正的正样本</p>
  </li>
  <li>
    <p><strong>召回率</strong>(Recall) = $\tfrac{TP}{TP+FN}$</p>

    <p>针对我们原来的<strong>样本</strong>而言的，表示的是样本中的正例有多少被预测正确了。</p>
  </li>
  <li>
    <p><strong>F-Measure</strong> = $\tfrac{(\alpha^2 + 1)P\times R}{\alpha^2 P + R}$</p>

    <p>为了解决精确率和召回率有时候会发生的冲突问题，我们引入F值来评估。</p>

    <p>常见的有F~1~值，是精确率和召回率的<strong>调和均值</strong>，令$\alpha = 1$则得到我们的F~1~值</p>
  </li>
</ul>

<p>上面的是基于分类问题的评估，而基于回归问题，我们有如下方法：</p>

<ul>
  <li>
    <p><strong>MAE</strong>(Mean Absolute Error), <strong>l1-norm loss</strong></p>

    <p><script type="math/tex">MAE(y, \hat{y})=\frac{1}{n_{samples}}\sum_{i=1}^{n_{samples}}\left|y_i-\hat{y_i}\right|</script>
<strong>MSE</strong>(Mean Squared Error), <strong>l2-norm loss</strong>
<script type="math/tex">MSE(y, \hat{y})=\frac{1}{n_{samples}}\sum_{i=1}^{n_{samples}}(y_i-\hat{y_i})^2</script>
以及还有衍生的$RMSE$, $MAPE$ 等方法就不一一介绍了。</p>

    <p>因为有项目涉及到, 这里再提一个smape, <strong>对称平均绝对百分比误差</strong>:</p>

    <p><strong>SMAPE</strong>(Symmetric Mean Absolute Percentage Error):
<script type="math/tex">SMAPE(y, \hat{y})=\frac{1}{n_{sample}}\sum^n_{i=1}\frac{\left|y_i-\hat{y_i}\right|}{(\left|\hat{y_i}\right|+\left|y_i\right|)/2})</script>
<em>注意：当真实值有数据等于0，而预测值也等于0时，存在分母0除问题，该公式不可用！</em></p>
  </li>
</ul>

<h4 id="12-精确率和召回率之间的权衡">1.2 精确率和召回率之间的权衡</h4>

<p>为了提高precision，分类器更偏向在更有把握时才把样本标为正，这样就会使得分类更加保守，从而漏掉很多本为正的真实样本，从而导师Recall降低。</p>

<p>所以评估模型好坏时，不能仅仅只看Recision和Recall，最好可以绘制模型的P-R Curve。</p>

<p>P-R Curve以Precision作为纵轴，Recall作为横轴，如下：</p>

<p><img src="../img/illustration/20190313-mlinterview11.png" width="350" /></p>

<p>PR曲线上的每个点都表示某个参数配置下模型的精确率和召回率。</p>

<p>此外还可以用<code class="highlighter-rouge">F1 Score</code>和<code class="highlighter-rouge">ROC曲线</code>来表示模型性能。</p>

<h4 id="13-rmse-的缺陷">1.3 RMSE 的缺陷</h4>

<p>首先RMSE的定义：$RMSE  = \sqrt{\frac{\sum_{i=1}^N(y_i-\hat{y_i})^2}{n}}$</p>

<p>实际问题中，如果存在个别离群点(Outliers)的离群成都非常大，即使数量很少，对RMSE也会产生很大的影响。</p>

<p>解决办法：</p>

<ul>
  <li>
    <p>如果认定离群点是”噪声“，那么在数据预处理的时候就可以去掉</p>
  </li>
  <li>
    <p>通过进一步的建模，把离群点的产生的机制建模进去</p>
  </li>
  <li>
    <p>寻找更适合的指标。比如MAPE(平均绝对百分比误差)</p>

    <p><script type="math/tex">MAPE=\sum_{i=1}^N\left|\frac{y_i-\hat{y_i}}{y_i}\right|\times\frac{100}{n}</script>
MAPE相比于RMSE，把每个点的误差做了归一化，降低了个别离群点带来的绝对误差的影响。</p>
  </li>
</ul>

<h3 id="2-roc曲线">2. ROC曲线</h3>

<h4 id="21-基础概念">2.1 基础概念</h4>

<ul>
  <li>
    <p><strong>ROC曲线</strong>(Receiver Operating Characteristic Curve): 横坐标表示FPR(False Positive Rate)，纵坐标表示TPR(True Positive Rate)。其中</p>

    <ul>
      <li>$FPR=\frac{FP}{FP+TN}$, 指在所有负样本中预测为正的比率（误报率）</li>
      <li>$TPR=\frac{TP}{TP+FN}$. 指在所有正样本中预测为正的比率（召回率）</li>
    </ul>
  </li>
  <li>
    <p><strong>AUC曲线</strong>(Area Under Curve): 即ROC曲线下面积。能够量化地反应基于ROC曲线衡量的模型性能。一般来说计算AUC只要对ROC曲线沿着横轴做积分就好了。</p>

    <p>ROC曲线一般都在$y=x$这条直线上方，所以AUC的值一般都在0.5～1之间，AUC越大说明模型越能把真正的正样本排在前面，分类性能越好。</p>
  </li>
</ul>

<h4 id="22-roc曲线和p-r曲线有什么区别">2.2 ROC曲线和P-R曲线有什么区别？</h4>

<p>当正负样本分布发生变化时，ROC曲线能够基本保持不变，但是P-R曲线一般会发生比较剧烈的变化。</p>

<p><img src="../img/illustration/20190313-mlinterview12.png" width="450" /></p>

<p>上图可以从一定程度说明，ROC曲线能够尽可能降低不同测试集带来的干扰，更加客观地反应模型性能。但是对这两种曲线的选择也要因问题而异。如果想要看到模型在特定测试集上的表现，P-R曲线可能就是更好的选择。</p>

<h3 id="3-模型评估方法">3. 模型评估方法</h3>

<h4 id="31-有哪些主要模型评估方法及其优缺点">3.1 有哪些主要模型评估方法，及其优缺点？</h4>

<ul>
  <li>
    <p><strong>Holdout</strong></p>

    <p>比较简单直接的方法，把原始数据机随机划分成训练集和测试集两部分。例如70%的样本用于模型训练，30%的样本用于模型验证，包括绘制ROC曲线，计算精确率，召回率等指标评估模型性能。</p>
  </li>
  <li>
    <p><strong>Cross-Validation</strong></p>

    <ul>
      <li>
        <p>k-fold cross-validation</p>

        <p>把数据集分成k份，每次训练把其中一份作为测试集，其余所有作为训练集。最后把k次评估的平均指标作为评估结果。通常k取5或10</p>
      </li>
      <li>
        <p>Leave one cross-validation</p>

        <p>把长度为n的数据集，每次训练取其中一个样本做测试， 其他都做训练集。最后平均每次的评估结果。</p>
      </li>
    </ul>
  </li>
  <li>
    <p><strong>BootStrap</strong></p>

    <p>对总长度为n的数据集，做n次有放回的随机抽样，得到长度为n的训练集，剩下没有被抽到的数据作为测试集。</p>
  </li>
</ul>

<h4 id="32-bootstrap随机抽样的过程中如果样本总数n趋向无穷大那么没有被抽到的数据有多少">3.2 BootStrap随机抽样的过程中，如果样本总数n趋向无穷大，那么没有被抽到的数据有多少？</h4>

<p>单个样本在单次采样过程中没有被抽到的概率为$(1-\frac{1}{n})$, 在n次采样中: $(1-\frac{1}{n})^n$,  所以当n趋向于正无穷时: $\lim_{i\to\infty}(1-\frac{1}{n})^n$.</p>

<p>根据<strong>重要极限</strong>（学好高数很重要）：$\lim_{i\to\infty}(1-\frac{1}{n})^n=e$</p>

<p><script type="math/tex">\lim_{i\to\infty}(1-\frac{1}{n})^n =  \lim_{i\to\infty}{\frac{1}{(1+\frac{1}{n-1})^n}} = \frac{1}{\lim_{i\to\infty}{(1+\frac{1}{n-1})^{n-1}}}\cdot\frac{1}{\lim_{i\to\infty}{(1+\frac{1}{n-1})}} = \frac{1}{e} \simeq 0.368</script>
因此当样本数量很大时，有约36.8%的样本没有被选择过，可以作为验证集。</p>

<h3 id="4-超参数调优">4. 超参数调优</h3>

<h4 id="41-超参数调优有哪些方法">4.1 超参数调优有哪些方法？</h4>

<ul>
  <li>
    <p><strong>超参数搜索算法包含哪些要素：</strong></p>

    <ul>
      <li>目标函数，算法需要最大化/最小化的目标，<em>可能是我们的 loss function</em></li>
      <li>搜索范围，一般需要指定搜索的上界和下界</li>
      <li>其他参数，比如搜索的步长，因算法而异</li>
    </ul>
  </li>
  <li>
    <p><strong>网格搜索</strong></p>

    <p>通过查找搜索范围内的所有点来确定最优值。如果用较大搜索范围和较小步长，有很大概率可以搜索到全局最优值，但是对计算资源需求比较高。</p>

    <p>实际使用中，一般先选取较大范围较大步长，确定最优解可能存在范围后再逐步缩小范围和步长。但是因为目标函数是<strong>非凸</strong>的，所以可能会跳过全局最优值。</p>
  </li>
  <li>
    <p><strong>随机搜索</strong></p>

    <p>在搜索范围内随机取样本点。只要样本点集足够大，那么就有很大概率可以找到全局最优值，或者其近似值。随机搜索一般比网格搜索快，但是其结果也没法保证。</p>
  </li>
  <li>
    <p><strong>贝叶斯优化算法</strong></p>

    <p>对<strong>目标函数的形状进行学习</strong>，找到使目标函数图像向全集最优值提升的参数。具体步骤是：</p>

    <ul>
      <li>根据先验分布，假设一个搜集函数</li>
      <li>每次采用新的样本点来测试目标函数，然后用这个信息来更新目标函数的先验分布</li>
      <li>算法测试由后验分布给出全局最优值可能出现的位置的点</li>
    </ul>

    <p>贝叶斯优化算法的问题在于有可能卡在局部最优点，所以算法会在”搜索“和”利用“之间找到一个平衡。即在为采样的区域<strong>“搜索”</strong>新的采样点，<strong>“利用”</strong>根据后验分布得出的全局最优值可能出现位置的采样点。</p>
  </li>
</ul>

<h3 id="5-过拟合与欠拟合">5. 过拟合与欠拟合</h3>

<h4 id="51-怎么降低过拟合或者欠拟合的风险">5.1 怎么降低过拟合或者欠拟合的风险？</h4>

<ul>
  <li>过拟合
    <ul>
      <li>增加训练数据量</li>
      <li>降低模型复杂度</li>
      <li>运用正则化方法</li>
      <li>运用集成学习的方法</li>
    </ul>
  </li>
  <li>欠拟合
    <ul>
      <li>增加新特征</li>
      <li>增加模型复杂度，增强模型的拟合能力</li>
      <li>减少正则化系数</li>
    </ul>
  </li>
</ul>

<h3 id="6-alphabeta-测试">6. $\alpha/\beta$ 测试</h3>

<h4 id="61-为什么还要进行ab测试">6.1 为什么还要进行A/B测试？</h4>

<ul>
  <li>离线测试不能完全避免过拟合的风险</li>
  <li>离线评估无法还原真实的工作场景。一般的，离线评估无法完整包括线上使用时存在的延迟，数据丢失，标签数据缺失等情况</li>
  <li>线上系统所需要的一些商业指标，在线下测试中无法被包含。比如新上线的推荐算法，线下测试关注的是模型本身的ROC曲线，P-R曲线，但是线上测试更关注的是该算法带来的用户点击率，留存时长和PV访问量的增长。</li>
</ul>

<h4 id="62-如何进行ab测试">6.2 如何进行A/B测试？</h4>

<p>对用户进行分箱，分为实验组和对照组。实验组施以新模型，对照组施以旧模型。分箱过程中要注意到用户样本的独立性和无偏性。</p>

<h3 id="7-余弦距离">7. 余弦距离</h3>

<h4 id="71-基础概念">7.1 基础概念</h4>

<ul>
  <li>
    <p><strong>余弦距离</strong>：$dist(A,B)=1-cos\angle(A,B)$</p>
  </li>
  <li>
    <p><strong>欧式距离</strong>体现距离上的绝对差异，而<strong>余弦距离</strong>体现方向上的相对差异。比如分析用户观看行为偏好，那么比较两个用户在不同视频上的偏好，应该采用余弦距离，而对比用户在视频上花费的时间则选用欧式距离。</p>
  </li>
</ul>

<h4 id="72-余弦距离是严格定义的距离吗">7.2 余弦距离是严格定义的距离吗？</h4>

<ul>
  <li>在集合中，一对元素之间存在唯一的一个$d\in\mathbb R$, 使得三条距离公理成立（Norm的条件: 正定性，对称性，三角不等性），则称$d$为这对元素之间的距离</li>
  <li>余弦距离满足正定性和对称性，但是不满足三角不等性</li>
  <li>机器学习领域中的距离，除了余弦距离，还有KL距离（Kullback-Leibler Divergence）也叫相对熵，也不符合三角不等性。</li>
</ul>

:ET